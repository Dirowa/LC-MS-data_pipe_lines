# LC-MS2 data dynamic pipeline for metabolomic biomarker discovery

## the wrapper
The LC-MS2 wrapper is not an ordinary data-pipeline.
Due the the huge amounts of variables and options is an dynamic pipeline created with an shell based interface
With the Shell based interface is it possible to analyse datasets by remote computing
The wrapper can be initialised by python and supports the Windows and Linux OS. 

#### wrapper functions

inside the wrapper are serveral inbuild functions to improve functionality
When the wrapper is excecuted for the first time it will generate a few importand setting files which worked when testing the data pipeline
These settings can be adjusted inside the Shell system also by just using copy and paste. paths will be directly put in the right format.
The settings can also be adjusted by opening the txt file and adjust the items "note keep the same layout or the wrapper will not know anymore what to do"
When running an script from the wrapper a choise menu will be opend. users can fill in their adjustments to the Default settings or press ENTER for the default setting.
After choosing the variables it will produce a txt file in the script_settings folder with the used settings to keep a track on which settings used.
These files can also be used as import as settings to the data_pipeline when running a script.

A batch run can be used. the files required for that can be found in the Batch folder with example setting file. This can be adjusted to server your needs. 

To Analyse the data a few options are made available
##### full run

with the full run the imported datasets will go through almost all available scripts.
It runs from XCMS peakpicking > batch Correction > pre univariate filtering > univariate testing > post univariate filtering > database annotation

##### batch run
The batch run does the same as the full run for exception on that you will get a choice meneu to enter variables. for this the example files in the Batch folders has to be edited and possible duplicated for more runs. it is advised to test the used variables first with part run

##### part run 
in the part run all scripts can be manualy enterd or give a path to a file containing the settings. The Scripts are written in that way that i will accept all output formats from other scripts used for maximal flexibillity. the part runs also contains Majority Vote calculations which is needed to create venn diagrams. The input from the Majority vote script is the annotated xlsx. file generated by database annotation. used can decide on which factor it is wished to make a Majority Vote on. 

## datasets
with the datasets is it important to have the following items in the Sample Meta data
It requires The sample names, Batch number, injection orders and sampletypes.
incase batch is unknown run serveral PCA plots todecide or fill in 1 with all samples.
The injection order is the order from oldest to youngest when data is analysed by the LC-MS
in the sampletypes are the following information required. Blanks, Qc (or pooled samples) and samples, Internstal standards are not yet incorperated into this data-pipeline.

## databases
the databases are generated by Using MetaboShiny.
Installing MetaboShiny can be quite troublesome, for that check "Tips_for_installing_metaboshiny_on_clean_linux.R" to install dependencies for a clean Linux system
Metaboshiny parsers small public databases and generetes from the SMILE formula the monoisotopic mass.
Later in the datapipeline compounds will be filterd for the monoisotopic mass
It is also possible to parse pubchem into metadobo Shiny. For this are 2 Python scripts created
1-  PubChem_parser_to import_to_extended.py can be run and the produces files have to be manually enterd in the extended.db from metaboshiny with SQLite3 commands.
2-  pubchem_parser_slow_window&linux.py does the same as PubChem_parser_to import_to_extended.py but the output files can be imported into Metaboshiny where it calculates the monoisotopic mass from the SMILES structure

## scripts in data pipeline.

#### XCMS peakpicking
XCMS is chosen as peakpicking algorithm due the high custombillity, Relative processing speed, RAM and CPU usage and the amount of covering significant features. 
In this script. peaks will be analysed by using the CentwaveParam, the found features will be merged together incase of splitted peaks  by the MergeNeighboringPeaksParam.
All found peaks will be corrected for their retention time based on well behaving peak (peaks found across all samples) which is done by the Obiwarpparam algorithm. After the retention time correction the FillChrompeaksparam will look back on all samples to fill in missing peak of which first was not detected. All peaks will then be grouped into features. The found Features will be analysed by the CAMERA package to find Adducts, Isotope labeling and group them into pseudospectras.
The dataframes names and values will be edited so other scripts will accepts them and not fall into an error. This reduces the amount of unnesacary filling variables.

#### Batch Correction

